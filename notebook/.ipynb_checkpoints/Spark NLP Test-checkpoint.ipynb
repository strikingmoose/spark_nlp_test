{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark NLP Test\n",
    "This notebook explores the use of Spark NLP which contains built in, parallelized NLP methods accessible via Apache Spark. Spark NLP includes many basic functionalities such as tokenizers, lemmatizers, and stemmers. Spark NLP also has pre-built pipelines which include man yof these functionalities in a single pipeline function.\n",
    "\n",
    "This notebook was created with a Spark cluster running on AWS EMR.\n",
    "\n",
    "Inputs: Random set of twitter data (500K+ rows)\n",
    "Outputs: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install some initial repositories\n",
    "import os\n",
    "os.system(\"sudo /usr/bin/pip-3.4 install findspark pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use findspark package to connect Jupyter to Spark shell\n",
    "import findspark\n",
    "findspark.init('/usr/lib/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SparkSession object\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Load other libraries\n",
    "from datetime import datetime\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import DateType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set jupyter display options\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark NLP Setup & Configuration\n",
    "First, we have to download Spark NLP. Currently, for the Python version of Spark NLP, there is a more involved process of installation. First, we have to use the --packages method of installation with Spark as this is the standard way of installing and including packages, including downloading all its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spark nlp using the --packages method\n",
    "pyspark_submit_args = '--packages JohnSnowLabs:spark-nlp:1.5.3 pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a spark session to kick off the package download\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the dependencies installed automatically, we have to load and use the package itself using the --jar method. This is required as Spark NLP is still in initial development stages for Python and the .jar file is required and should be explicitly included so Python can access the Python wrappers included within the .jar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the jar file to provide python the appropriate wrapper for operation\n",
    "jar_source = u'http://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.11/1.5.3/spark-nlp_2.11-1.5.3.jar'\n",
    "jar_target = u'/home/hadoop/spark_nlp_test/data/spark-nlp_2.11-1.5.3.jar'\n",
    "os.system('wget -O {} {}'.format(jar_target, jar_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spark nlp a second time using the --jar method\n",
    "pyspark_submit_args = ' --jars /home/hadoop/spark_nlp_test/data/spark-nlp_2.11-1.5.3.jar pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "os.environ[\"PYTHONPATH\"] = jar_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the jar to path so python can use the python wrapper\n",
    "import sys\n",
    "import glob\n",
    "sys.path.extend(glob.glob(os.path.join(os.path.expanduser(\"~\"), \".ivy2/jars/*.jar\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SparkSession as \"spark\"\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spark nlp processing libraries\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Let's load 500K+ #metoo tweets (random data set for the purpose of testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tweet data\n",
    "tweets_df = spark.read.csv(\n",
    "    \"s3n://2017edmfasatb/spark_nlp_test/metootweets.csv\", \n",
    "    header = True, \n",
    "    inferSchema = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- insertdate: string (nullable = true)\n",
      " |-- twitterhandle: string (nullable = true)\n",
      " |-- followers: string (nullable = true)\n",
      " |-- hashtagsearched: string (nullable = true)\n",
      " |-- tweetid: string (nullable = true)\n",
      " |-- dateoftweet: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- lastcontactdate: string (nullable = true)\n",
      " |-- lasttimelinepull: string (nullable = true)\n",
      " |-- lasttimetweetsanalyzed: string (nullable = true)\n",
      " |-- numberoftweetsanalysed: string (nullable = true)\n",
      " |-- numberoftweetsabouthash: string (nullable = true)\n",
      " |-- actualtwitterdate: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview schema\n",
    "tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552180"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of rows\n",
    "tweets_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @IxAmandaDelgado: @Navegaciones @FelipeCalderon @comsatori Cuando esta se?ora habla es como leer los twits de Ivanka Trump con el HT #Me?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @alexwitze: .@NSF will require institutions that receive grant funds to tell them if PIs, co-PIs or anyone on the grant is found to have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the #metoo movement? https://t.co/aeoOhchgwA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>???????????????????????????????????????????????????????????? https://t.co/gWAWGlKa36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @AlbertoBernalLe: ?A ver, donde est?n todas las voceras colombianas del #MeToo? ?No van a decir nada ante esto? ?De verdad se van a qued?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           text\n",
       "0  RT @IxAmandaDelgado: @Navegaciones @FelipeCalderon @comsatori Cuando esta se?ora habla es como leer los twits de Ivanka Trump con el HT #Me?\n",
       "1  RT @alexwitze: .@NSF will require institutions that receive grant funds to tell them if PIs, co-PIs or anyone on the grant is found to have?\n",
       "2  Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the #metoo movement? https://t.co/aeoOhchgwA\n",
       "3                                                          ???????????????????????????????????????????????????????????? https://t.co/gWAWGlKa36\n",
       "4  RT @AlbertoBernalLe: ?A ver, donde est?n todas las voceras colombianas del #MeToo? ?No van a decir nada ante esto? ?De verdad se van a qued?"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview tweets\n",
    "tweets_df.limit(5).toPandas()[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "Let's remove \"RT\" labels for retweets, @ mentions, hashtags, and URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RT label\n",
    "tweets_df = tweets_df.withColumn('text_clean', F.regexp_replace(\n",
    "    F.col('text'),\n",
    "    'RT',\n",
    "    ''\n",
    "))\n",
    "\n",
    "# @ mentions\n",
    "tweets_df = tweets_df.withColumn('text_clean', F.regexp_replace(\n",
    "    F.col('text_clean'),\n",
    "    '@[A-Za-z0-9]+',\n",
    "    ''\n",
    "))\n",
    "\n",
    "# Hashtags\n",
    "tweets_df = tweets_df.withColumn('text_clean', F.regexp_replace(\n",
    "    F.col('text_clean'),\n",
    "    '#[A-Za-z0-9]+',\n",
    "    ''\n",
    "))\n",
    "\n",
    "# URLs\n",
    "tweets_df = tweets_df.withColumn('text_clean', F.regexp_replace(\n",
    "    F.col('text_clean'),\n",
    "    'https?[\\S]+',\n",
    "    ''\n",
    "))\n",
    "\n",
    "# Remove anything remaining that is not a word\n",
    "tweets_df = tweets_df.withColumn('text_clean', F.regexp_replace(\n",
    "    F.col('text_clean'),\n",
    "    '[^A-Za-z0-9 ]+',\n",
    "    ''\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @IxAmandaDelgado: @Navegaciones @FelipeCalderon @comsatori Cuando esta se?ora habla es como leer los twits de Ivanka Trump con el HT #Me?</td>\n",
       "      <td>Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @alexwitze: .@NSF will require institutions that receive grant funds to tell them if PIs, co-PIs or anyone on the grant is found to have?</td>\n",
       "      <td>will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the #metoo movement? https://t.co/aeoOhchgwA</td>\n",
       "      <td>Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>???????????????????????????????????????????????????????????? https://t.co/gWAWGlKa36</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @AlbertoBernalLe: ?A ver, donde est?n todas las voceras colombianas del #MeToo? ?No van a decir nada ante esto? ?De verdad se van a qued?</td>\n",
       "      <td>A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           text  \\\n",
       "0  RT @IxAmandaDelgado: @Navegaciones @FelipeCalderon @comsatori Cuando esta se?ora habla es como leer los twits de Ivanka Trump con el HT #Me?   \n",
       "1  RT @alexwitze: .@NSF will require institutions that receive grant funds to tell them if PIs, co-PIs or anyone on the grant is found to have?   \n",
       "2  Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the #metoo movement? https://t.co/aeoOhchgwA   \n",
       "3                                                          ???????????????????????????????????????????????????????????? https://t.co/gWAWGlKa36   \n",
       "4  RT @AlbertoBernalLe: ?A ver, donde est?n todas las voceras colombianas del #MeToo? ?No van a decir nada ante esto? ?De verdad se van a qued?   \n",
       "\n",
       "                                                                                                                text_clean  \n",
       "0                                                Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT   \n",
       "1     will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have  \n",
       "2           Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement   \n",
       "3                                                                                                                           \n",
       "4                A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview tweets\n",
    "tweets_df.limit(5).toPandas()[['text', 'text_clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark NLP\n",
    "Let's try to run some basic NLP functions using Spark NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize document assembler\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text_clean\")\n",
    "        \n",
    "# Transform\n",
    "tweets_df = document_assembler.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT</td>\n",
       "      <td>[(document, 0, 77,      Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT , {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have</td>\n",
       "      <td>[(document, 0, 118,    will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have, {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement</td>\n",
       "      <td>[(document, 0, 109, Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement , {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>[(document, 0, 0,  , {})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued</td>\n",
       "      <td>[(document, 0, 106,   A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued, {})]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                text_clean  \\\n",
       "0                                                Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT    \n",
       "1     will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have   \n",
       "2           Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement    \n",
       "3                                                                                                                            \n",
       "4                A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued   \n",
       "\n",
       "                                                                                                                                            document  \n",
       "0                                            [(document, 0, 77,      Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT , {})]  \n",
       "1  [(document, 0, 118,    will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have, {})]  \n",
       "2           [(document, 0, 109, Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement , {})]  \n",
       "3                                                                                                                          [(document, 0, 0,  , {})]  \n",
       "4              [(document, 0, 106,   A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued, {})]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataset\n",
    "tweets_df.limit(5).toPandas()[['text_clean', 'document']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize tokenizer\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "# Transform\n",
    "tweets_df = tokenizer.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(document, 0, 77,      Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT , {})]</td>\n",
       "      <td>[(token, 5, 10, Cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, Ivanka, {'sentence': '1'}), (token, 62, 66, Trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, HT, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(document, 0, 118,    will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have, {})]</td>\n",
       "      <td>[(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, PIs, {'sentence': '1'}), (token, 74, 78, coPIs, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(document, 0, 109, Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement , {})]</td>\n",
       "      <td>[(token, 0, 8, Listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, Cynthia, {'sentence': '1'}), (token, 50, 54, Enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(document, 0, 0,  , {})]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(document, 0, 106,   A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued, {})]</td>\n",
       "      <td>[(token, 2, 2, A, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, No, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, De, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            document  \\\n",
       "0                                            [(document, 0, 77,      Cuando esta seora habla es como leer los twits de Ivanka Trump con el HT , {})]   \n",
       "1  [(document, 0, 118,    will require institutions that receive grant funds to tell them if PIs coPIs or anyone on the grant is found to have, {})]   \n",
       "2           [(document, 0, 109, Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the  movement , {})]   \n",
       "3                                                                                                                          [(document, 0, 0,  , {})]   \n",
       "4              [(document, 0, 106,   A ver donde estn todas las voceras colombianas del  No van a decir nada ante esto De verdad se van a qued, {})]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       token  \n",
       "0                                                                                                                                                                                                                                                                                                                        [(token, 5, 10, Cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, Ivanka, {'sentence': '1'}), (token, 62, 66, Trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, HT, {'sentence': '1'})]  \n",
       "1  [(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, PIs, {'sentence': '1'}), (token, 74, 78, coPIs, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]  \n",
       "2                                                                                                                                                                                                                                                                                   [(token, 0, 8, Listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, Cynthia, {'sentence': '1'}), (token, 50, 54, Enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         []  \n",
       "4                     [(token, 2, 2, A, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, No, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, De, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataset\n",
    "tweets_df.limit(5).toPandas()[['document', 'token']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize normalizer\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normal\")\n",
    "    \n",
    "# Transform\n",
    "tweets_df = normalizer.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(token, 5, 10, Cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, Ivanka, {'sentence': '1'}), (token, 62, 66, Trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, HT, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 5, 10, cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, ivanka, {'sentence': '1'}), (token, 62, 66, trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, ht, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, PIs, {'sentence': '1'}), (token, 74, 78, coPIs, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, pis, {'sentence': '1'}), (token, 74, 78, copis, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(token, 0, 8, Listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, Cynthia, {'sentence': '1'}), (token, 50, 54, Enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 0, 8, listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, cynthia, {'sentence': '1'}), (token, 50, 54, enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(token, 2, 2, A, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, No, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, De, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 2, 2, a, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, no, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, de, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       token  \\\n",
       "0                                                                                                                                                                                                                                                                                                                        [(token, 5, 10, Cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, Ivanka, {'sentence': '1'}), (token, 62, 66, Trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, HT, {'sentence': '1'})]   \n",
       "1  [(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, PIs, {'sentence': '1'}), (token, 74, 78, coPIs, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]   \n",
       "2                                                                                                                                                                                                                                                                                   [(token, 0, 8, Listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, Cynthia, {'sentence': '1'}), (token, 50, 54, Enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         []   \n",
       "4                     [(token, 2, 2, A, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, No, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, De, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      normal  \n",
       "0                                                                                                                                                                                                                                                                                                                        [(token, 5, 10, cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, ivanka, {'sentence': '1'}), (token, 62, 66, trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, ht, {'sentence': '1'})]  \n",
       "1  [(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, pis, {'sentence': '1'}), (token, 74, 78, copis, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]  \n",
       "2                                                                                                                                                                                                                                                                                   [(token, 0, 8, listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, cynthia, {'sentence': '1'}), (token, 50, 54, enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         []  \n",
       "4                     [(token, 2, 2, a, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, no, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, de, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataset\n",
    "tweets_df.limit(5).toPandas()[['token', 'normal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pre-trained lemmatizer\n",
    "from sparknlp.annotator import LemmatizerModel\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "    .setInputCols(['normal']) \\\n",
    "    .setOutputCol('lemma')\n",
    "\n",
    "# Transform\n",
    "tweets_df = lemmatizer.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(token, 5, 10, cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, ivanka, {'sentence': '1'}), (token, 62, 66, trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, ht, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 5, 10, cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twit, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, ivanka, {'sentence': '1'}), (token, 62, 66, trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, ht, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, pis, {'sentence': '1'}), (token, 74, 78, copis, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institution, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, fund, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, they, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, pi, {'sentence': '1'}), (token, 74, 78, copis, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, be, {'sentence': '1'}), (token, 106, 110, find, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(token, 0, 8, listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, cynthia, {'sentence': '1'}), (token, 50, 54, enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 0, 8, listen, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, cynthia, {'sentence': '1'}), (token, 50, 54, enloe, {'sentence': '1'}), (token, 56, 63, speak, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(token, 2, 2, a, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, no, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, de, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]</td>\n",
       "      <td>[(token, 2, 2, a, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, la, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, no, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, de, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      normal  \\\n",
       "0                                                                                                                                                                                                                                                                                                                        [(token, 5, 10, cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twits, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, ivanka, {'sentence': '1'}), (token, 62, 66, trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, ht, {'sentence': '1'})]   \n",
       "1  [(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institutions, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, funds, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, them, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, pis, {'sentence': '1'}), (token, 74, 78, copis, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, is, {'sentence': '1'}), (token, 106, 110, found, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]   \n",
       "2                                                                                                                                                                                                                                                                                   [(token, 0, 8, listening, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, cynthia, {'sentence': '1'}), (token, 50, 54, enloe, {'sentence': '1'}), (token, 56, 63, speaking, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         []   \n",
       "4                     [(token, 2, 2, a, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, las, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, no, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, de, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   lemma  \n",
       "0                                                                                                                                                                                                                                                                                                                     [(token, 5, 10, cuando, {'sentence': '1'}), (token, 12, 15, esta, {'sentence': '1'}), (token, 17, 21, seora, {'sentence': '1'}), (token, 23, 27, habla, {'sentence': '1'}), (token, 29, 30, es, {'sentence': '1'}), (token, 32, 35, como, {'sentence': '1'}), (token, 37, 40, leer, {'sentence': '1'}), (token, 42, 44, los, {'sentence': '1'}), (token, 46, 50, twit, {'sentence': '1'}), (token, 52, 53, de, {'sentence': '1'}), (token, 55, 60, ivanka, {'sentence': '1'}), (token, 62, 66, trump, {'sentence': '1'}), (token, 68, 70, con, {'sentence': '1'}), (token, 72, 73, el, {'sentence': '1'}), (token, 75, 76, ht, {'sentence': '1'})]  \n",
       "1  [(token, 3, 6, will, {'sentence': '1'}), (token, 8, 14, require, {'sentence': '1'}), (token, 16, 27, institution, {'sentence': '1'}), (token, 29, 32, that, {'sentence': '1'}), (token, 34, 40, receive, {'sentence': '1'}), (token, 42, 46, grant, {'sentence': '1'}), (token, 48, 52, fund, {'sentence': '1'}), (token, 54, 55, to, {'sentence': '1'}), (token, 57, 60, tell, {'sentence': '1'}), (token, 62, 65, they, {'sentence': '1'}), (token, 67, 68, if, {'sentence': '1'}), (token, 70, 72, pi, {'sentence': '1'}), (token, 74, 78, copis, {'sentence': '1'}), (token, 80, 81, or, {'sentence': '1'}), (token, 83, 88, anyone, {'sentence': '1'}), (token, 90, 91, on, {'sentence': '1'}), (token, 93, 95, the, {'sentence': '1'}), (token, 97, 101, grant, {'sentence': '1'}), (token, 103, 104, be, {'sentence': '1'}), (token, 106, 110, find, {'sentence': '1'}), (token, 112, 113, to, {'sentence': '1'}), (token, 115, 118, have, {'sentence': '1'})]  \n",
       "2                                                                                                                                                                                                                                                                                     [(token, 0, 8, listen, {'sentence': '1'}), (token, 10, 11, to, {'sentence': '1'}), (token, 13, 15, the, {'sentence': '1'}), (token, 17, 23, awesome, {'sentence': '1'}), (token, 25, 32, feminist, {'sentence': '1'}), (token, 34, 40, scholar, {'sentence': '1'}), (token, 42, 48, cynthia, {'sentence': '1'}), (token, 50, 54, enloe, {'sentence': '1'}), (token, 56, 63, speak, {'sentence': '1'}), (token, 65, 69, about, {'sentence': '1'}), (token, 71, 73, the, {'sentence': '1'}), (token, 75, 86, relationship, {'sentence': '1'}), (token, 88, 94, between, {'sentence': '1'}), (token, 96, 98, the, {'sentence': '1'}), (token, 101, 108, movement, {'sentence': '1'})]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     []  \n",
       "4                  [(token, 2, 2, a, {'sentence': '1'}), (token, 4, 6, ver, {'sentence': '1'}), (token, 8, 12, donde, {'sentence': '1'}), (token, 14, 17, estn, {'sentence': '1'}), (token, 19, 23, todas, {'sentence': '1'}), (token, 25, 27, la, {'sentence': '1'}), (token, 29, 35, voceras, {'sentence': '1'}), (token, 37, 47, colombianas, {'sentence': '1'}), (token, 49, 51, del, {'sentence': '1'}), (token, 54, 55, no, {'sentence': '1'}), (token, 57, 59, van, {'sentence': '1'}), (token, 61, 61, a, {'sentence': '1'}), (token, 63, 67, decir, {'sentence': '1'}), (token, 69, 72, nada, {'sentence': '1'}), (token, 74, 77, ante, {'sentence': '1'}), (token, 79, 82, esto, {'sentence': '1'}), (token, 84, 85, de, {'sentence': '1'}), (token, 87, 92, verdad, {'sentence': '1'}), (token, 94, 95, se, {'sentence': '1'}), (token, 97, 99, van, {'sentence': '1'}), (token, 101, 101, a, {'sentence': '1'}), (token, 103, 106, qued, {'sentence': '1'})]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataset\n",
    "tweets_df.limit(5).toPandas()[['normal', 'lemma']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize finisher\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setAnnotationSplitSymbol(' ') \n",
    "    \n",
    "# Transform\n",
    "tweets_df = finisher.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>finished_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @IxAmandaDelgado: @Navegaciones @FelipeCalderon @comsatori Cuando esta se?ora habla es como leer los twits de Ivanka Trump con el HT #Me?</td>\n",
       "      <td>cuando esta seora habla es como leer los twit de ivanka trump con el ht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @alexwitze: .@NSF will require institutions that receive grant funds to tell them if PIs, co-PIs or anyone on the grant is found to have?</td>\n",
       "      <td>will require institution that receive grant fund to tell they if pi copis or anyone on the grant be find to have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the #metoo movement? https://t.co/aeoOhchgwA</td>\n",
       "      <td>listen to the awesome feminist scholar cynthia enloe speak about the relationship between the movement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>???????????????????????????????????????????????????????????? https://t.co/gWAWGlKa36</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @AlbertoBernalLe: ?A ver, donde est?n todas las voceras colombianas del #MeToo? ?No van a decir nada ante esto? ?De verdad se van a qued?</td>\n",
       "      <td>a ver donde estn todas la voceras colombianas del no van a decir nada ante esto de verdad se van a qued</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           text  \\\n",
       "0  RT @IxAmandaDelgado: @Navegaciones @FelipeCalderon @comsatori Cuando esta se?ora habla es como leer los twits de Ivanka Trump con el HT #Me?   \n",
       "1  RT @alexwitze: .@NSF will require institutions that receive grant funds to tell them if PIs, co-PIs or anyone on the grant is found to have?   \n",
       "2  Listening to the awesome feminist scholar Cynthia Enloe speaking about the relationship between the #metoo movement? https://t.co/aeoOhchgwA   \n",
       "3                                                          ???????????????????????????????????????????????????????????? https://t.co/gWAWGlKa36   \n",
       "4  RT @AlbertoBernalLe: ?A ver, donde est?n todas las voceras colombianas del #MeToo? ?No van a decir nada ante esto? ?De verdad se van a qued?   \n",
       "\n",
       "                                                                                                     finished_lemma  \n",
       "0                                           cuando esta seora habla es como leer los twit de ivanka trump con el ht  \n",
       "1  will require institution that receive grant fund to tell they if pi copis or anyone on the grant be find to have  \n",
       "2            listen to the awesome feminist scholar cynthia enloe speak about the relationship between the movement  \n",
       "3                                                                                                                    \n",
       "4           a ver donde estn todas la voceras colombianas del no van a decir nada ante esto de verdad se van a qued  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview dataset\n",
    "tweets_df.limit(5).toPandas()[['text', 'finished_lemma']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
